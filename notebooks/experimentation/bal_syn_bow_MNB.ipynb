{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to experiment with oversamplirg techniques on the dataset and then apply BOW and Multinomial Naive Bayes as our balanced baseline model to have a reference in our experimentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from mlflow.models import infer_signature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../../data/gold/train.csv\")\n",
    "test = pd.read_csv(\"../../data/gold/test.csv\")\n",
    "val = pd.read_csv(\"../../data/gold/validation.csv\")\n",
    "X_train = train['features']\n",
    "y_train = train['target']\n",
    "X_test = test['features']\n",
    "y_test = test['target']\n",
    "signature = infer_signature(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SPAM rows of our dataset for modelling is: 517\n",
      "The HAM rows of our dataset for modelling is: 3606\n",
      "The total rows of our dataset for modelling is: 4123\n",
      "We have to create 3089 rows to balance the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_rows = train[train['target'] == 1].value_counts().sum()\n",
    "print(f\"The SPAM rows of our dataset for modelling is: {spam_rows}\")\n",
    "ham_rows = train[train['target'] == 0].value_counts().sum()\n",
    "print(f\"The HAM rows of our dataset for modelling is: {ham_rows}\")\n",
    "\n",
    "print(f\"The total rows of our dataset for modelling is: {len(train)}\")\n",
    "rows_to_create = ham_rows - spam_rows\n",
    "print(f\"We have to create {rows_to_create} rows to balance the dataset\")\n",
    "\n",
    "spam_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy is to repeat the rows until a condition (having 3606 lines) is met. Then take those rows and apply transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'words' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# flat_list = X_train.values.flatten().tolist()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m text_aug \u001b[38;5;241m=\u001b[39m TextAugmentation(alpha_sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, alpha_ri\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, alpha_rs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, p_rd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_aug\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m augmented_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mtext_aug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Ver las oraciones aumentadas\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aug_sentence \u001b[38;5;129;01min\u001b[39;00m augmented_sentences:\n",
      "File \u001b[0;32m~/dscience/projects/spam_detector/notebooks/experimentation/experiments_utils.py:130\u001b[0m, in \u001b[0;36mTextAugmentation.eda\u001b[0;34m(self, dataframe)\u001b[0m\n\u001b[1;32m    128\u001b[0m sentences \u001b[38;5;241m=\u001b[39m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mwords\u001b[49m\u001b[38;5;241m.\u001b[39mextend(sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    132\u001b[0m words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    133\u001b[0m num_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(words)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'words' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from experiments_utils import TextAugmentation\n",
    "\n",
    "# flat_list = X_train.values.flatten().tolist()\n",
    "\n",
    "text_aug = TextAugmentation(alpha_sr=0.2, alpha_ri=0.2, alpha_rs=0.2, p_rd=0.1, num_aug=30)\n",
    "\n",
    "augmented_sentences = text_aug.eda(train)\n",
    "\n",
    "# Ver las oraciones aumentadas\n",
    "for aug_sentence in augmented_sentences:\n",
    "    print(aug_sentence)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonims Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find synonims for the 50% of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_synonyms(text, replacement_prob=0.5):\n",
    "\n",
    "    words = text.split()  \n",
    "    new_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if random.random() < replacement_prob:  \n",
    "            synsets = wn.synsets(word)  \n",
    "            if synsets:\n",
    "                synonym = synsets[0].lemmas()[0].name()\n",
    "                if synonym.lower() != word.lower():  \n",
    "                    new_words.append(synonym)\n",
    "                    continue\n",
    "        \n",
    "        new_words.append(word)  \n",
    "    \n",
    "    return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete['features'] = df_complete['features'].apply(replace_with_synonyms)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train, df_complete])\n",
    "print(f\"Lenght of the new dataframe is: {len(combined_df)}\")\n",
    "\n",
    "sum_target_0 = combined_df[combined_df['target'] == 0].value_counts().sum()\n",
    "sum_target_1 = combined_df[combined_df['target'] == 1].value_counts().sum()\n",
    "print(f\"Total row sum for target = 0: {sum_target_0}\")\n",
    "print(f\"Total row sum for target = 1: {sum_target_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    \n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1, 1), max_features=None)),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report = classification_report(y_train, y_train_pred, target_names = ['ham', 'spam'], digits=3)\n",
    "print(\"Classification Report (Train Data):\")\n",
    "print(train_report)\n",
    "\n",
    "test_report = classification_report(y_test, y_test_pred, target_names = ['ham', 'spam'], digits=3)\n",
    "print(\"Classification Report (Test Data):\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_train_prob = pipeline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train ROC (AUC = {auc_train:.3f})', color='blue', linewidth=2)\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC (AUC = {auc_test:.3f})', color='red', linestyle='--', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=1, label='Random classifier')\n",
    "plt.title('ROC Curve', fontsize=16)\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "- Precision for SPAM drops, bad news...\n",
    "- Recall for SPAM gets a bit better.\n",
    "- F1-score obviously drops because of precision\n",
    "- Macro avg doesn't get better either...\n",
    "\n",
    "This model is not memorizing well on train since the metrics clearly bad than others at classying SPAM messages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F0.5-Score\n",
    "f0_5_score = fbeta_score(y_test, y_test_pred, beta=0.5)\n",
    "print(f\"F0.5-Score: {f0_5_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- f0.5-score: not that important since we have our dataset balanced now.\n",
    "- Precision: went down to 52% of the predicted positives are true positives.\n",
    "- Recall: 98% of the real positives are true positives.\n",
    "- F1-score: the model is doing a decent job on the label 0 but not on the label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "matrix_fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix, display_labels=['Ham', 'Spam'])\n",
    "cm_display.plot(cmap='Blues', ax=ax)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "The confusion matrix looks very good.\n",
    "- 57 e-mails were predicted as SPAM but they were HAM. (these are the ones I will try to minimize)\n",
    "- 1 e-mail1 was predicted as HAM but it was SPAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_test_pred_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "pr_fig, ax = plt.subplots(figsize=(8, 6))  \n",
    "ax.plot(recall, precision, color='b', label=f'PR AUC = {pr_auc:.2f}')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "The area under the curve is 0.98 so the model strikes a strong balance between precision and recall across thresholds. The model identifies spam effectively without producing excessive false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_pred_prob)\n",
    "\n",
    "print(f\"ROC AUC en entrenamiento: {roc_auc_train:.2f}\")\n",
    "print(f\"ROC AUC en prueba: {roc_auc_test:.2f}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils import experiment_status\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "experiment_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the console\n",
    "# mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts\n",
    "# mlflow.search_experiments()\n",
    "\n",
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()\n",
    "# client.delete_run(\"81b0d40ddc814076a95bc6fd9d4fff34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name, _, _ = experiment_status()\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MlFlow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "with mlflow.start_run(run_name=\"baseline-model\", log_system_metrics=True) as run:\n",
    "    \n",
    "    # Tags\n",
    "    mlflow.set_tag(\"dataset\", \"Spam detection\")\n",
    "    mlflow.set_tag(\"task\", \"classification\")\n",
    "    mlflow.set_tag(\"vectorizer\", \"CountVectorizer\")\n",
    "    mlflow.set_tag(\"algorithm\", \"Multinomial Naive Bayes\")\n",
    "    mlflow.set_tag(\"framework\", \"Scikit-learn\")\n",
    "    mlflow.set_tag(\"language\", \"Python\")\n",
    "    mlflow.set_tag(\"environment\", \"Local\")\n",
    "    mlflow.set_tag(\"dataset_version\", \"1.0.0\")\n",
    "    mlflow.set_tag(\"preprocessing_version\", \"1.0.0\")\n",
    "    mlflow.set_tag(\"model_version\", \"0.0.1\")\n",
    "    mlflow.set_tag(\"developer\", \"Mldu\")\n",
    "    mlflow.set_tag(\"project_stage\", \"testing\")\n",
    "\n",
    "    #Datasets\n",
    "    mlflow.log_input(mlflow.data.from_pandas(train, name=\"train dataset\", targets=\"target\"))\n",
    "    mlflow.log_input(mlflow.data.from_pandas(test, name=\"test dataset\", targets=\"target\"))\n",
    "    mlflow.log_input(mlflow.data.from_pandas(val, name=\"validation dataset\", targets=\"target\"))\n",
    "    mlflow.log_artifact(\"../../data/gold/train.csv\")\n",
    "    mlflow.log_artifact(\"../../data/gold/test.csv\")\n",
    "    mlflow.log_artifact(\"../../data/gold/validation.csv\")\n",
    "\n",
    "    \n",
    "    #BOW and model\n",
    "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
    "    mlflow.log_param(\"model_type\", \"MultinomialNB\")\n",
    "    \n",
    "    # Metrics\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"balanced_accuracy\", balanced_accuracy)\n",
    "    mlflow.log_metric(\"f0_5_score\", f0_5_score)\n",
    "    cr = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    mlflow.log_metric(\"accuracy\", cr.pop(\"accuracy\"))\n",
    "    for class_or_avg, metrics_dict in cr.items():\n",
    "        for metric, value in metrics_dict.items():\n",
    "            mlflow.log_metric(class_or_avg + '_' + metric,value)\n",
    "    \n",
    "    # Figures\n",
    "    mlflow.log_figure(matrix_fig, \"confusion-matrix.png\")\n",
    "    mlflow.log_figure(pr_fig, \"precision-recall-curve.png\")\n",
    "    \n",
    "    # CountVectorizer and MNB\n",
    "    mlflow.sklearn.log_model(pipeline, \"pipeline\",signature=signature)\n",
    "    \n",
    "    # Notebook's name as tag and save as artifact\n",
    "    notebook_name = os.path.basename(globals()['__vsc_ipynb_file__'])   \n",
    "    mlflow.set_tag(\"source_notebook\", f\"{notebook_name}\")\n",
    "    mlflow.log_artifact(f\"{notebook_name}\", artifact_path=\"notebooks\")\n",
    "\n",
    "\n",
    "    print(f\"Pipeline logged to MLflow under run ID {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "- Clear overfitting \n",
    "- The model is not predicting at random since the accuracy is higher than the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam-detector-P2ybB3t6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
